# ORIGINAL DATA SET- Dr. Xu said Junk features in data so leaned towards classifiers that implicitly select features- Because there is no detail on what each feature is, difficult to intuitively deduce anything- Examining the missingness in each feature, 299.9 missing examples per feature    - Only 3 rows with 0 missingness    - Both classes missing data at the same rate (20%)- None of the features are normal, and its not close    - Implies that mean imputation is probably not good- Some features are very poorly behaved, conside feature 16 which is always 0 in the training data when class is 1- Some features are correlated    14 & 21: 0.907269    0 & 26: 0.705438    - Consider using PCA and l1 Logistic Regression to eliminate correlated features- Obviously high dimensional data, KNN will suffer curse of dimensionality, unlikely to be good without heavy feature selection or extraction- Imputation strategy quite important here, I think for something other than# General Model Selection OutputsClassifier: Med. Imp, PCA, KNN, Mean AUC 10-fold CV: 0.864 +/- 0.026, Mean TPR @ 1% FPR (10-fold CV): 0.268 +/- 0.092Classifier: Knn Imp, PCA, KNN, Mean AUC 10-fold CV: 0.862 +/- 0.032, Mean TPR @ 1% FPR (10-fold CV): 0.292 +/- 0.120Classifier: Med. Imp, LR(L1) FS, LR(L2), Mean AUC 10-fold CV: 0.897 +/- 0.023, Mean TPR @ 1% FPR (10-fold CV): 0.237 +/- 0.176Classifier: Med. Imp, RF, Mean AUC 10-fold CV: 0.909 +/- 0.023, Mean TPR @ 1% FPR (10-fold CV): 0.356 +/- 0.131Classifier: Knn Imp, RF, Mean AUC 10-fold CV: 0.895 +/- 0.032, Mean TPR @ 1% FPR (10-fold CV): 0.345 +/- 0.133Classifier: Med. Imp, RF FS, SVC, Mean AUC 10-fold CV: 0.814 +/- 0.035, Mean TPR @ 1% FPR (10-fold CV): 0.171 +/- 0.086Classifier: Mean Imp, Gaussian NB, Mean AUC 10-fold CV: 0.825 +/- 0.037, Mean TPR @ 1% FPR (10-fold CV): 0.157 +/- 0.093# Model Tuning and Actual Selection- Most interesting: bagged KNN, RF, Â¿XGB?- Bagged NB is just not complex enough- Found that, using learning curves:    - RF Was massively overfitting, TPR@FPR 0.9-1 on training, less than 0.4 on testing    - Bagged KNN also overfitting but less    ## RUN 1(10-fold, 100-iters, RS = 1)================================================================================Bagged kNN--------------------------------------------------------------------------------Best params:  baggingclassifier__bootstrap: False  baggingclassifier__bootstrap_features: True  baggingclassifier__estimator__n_neighbors: 1  baggingclassifier__estimator__p: 1  baggingclassifier__estimator__weights: distance  baggingclassifier__max_features: 0.7623351545618668  baggingclassifier__max_samples: 0.9473655792795455  baggingclassifier__n_estimators: 151Best CV TPR@1% FPR: 0.3867ROC AUC at best TPR point: 0.9022================================================================================Random Forest--------------------------------------------------------------------------------Best params:  randomforestclassifier__class_weight: balanced_subsample  randomforestclassifier__max_depth: 5  randomforestclassifier__max_features: log2  randomforestclassifier__min_samples_leaf: 4  randomforestclassifier__min_samples_split: 17  randomforestclassifier__n_estimators: 399Best CV TPR@1% FPR: 0.4013ROC AUC at best TPR point: 0.9141================================================================================XGBoost--------------------------------------------------------------------------------Best params:  xgbclassifier__colsample_bytree: 0.5326858575211132  xgbclassifier__gamma: 0.022656845652192913  xgbclassifier__learning_rate: 0.008511333444561585  xgbclassifier__max_depth: 2  xgbclassifier__min_child_weight: 2  xgbclassifier__n_estimators: 1103  xgbclassifier__reg_alpha: 0.046043516312527503  xgbclassifier__reg_lambda: 0.006075279473824769  xgbclassifier__subsample: 0.5830142409824424Best CV TPR@1% FPR: 0.4027ROC AUC at best TPR point: 0.9209################################################################################Leaderboard (by CV TPR@1% FPR)################################################################################XGBoost         | TPR@1%FPR:  0.4027 | ROC AUC:  0.9209Random Forest   | TPR@1%FPR:  0.4013 | ROC AUC:  0.9141Bagged kNN      | TPR@1%FPR:  0.3867 | ROC AUC:  0.9022## RUN 2Fitting 5 folds for each of 50 candidates, totalling 250 fits(RS = 420)================================================================================Bagged kNN--------------------------------------------------------------------------------Best params:  baggingclassifier__bootstrap: True  baggingclassifier__bootstrap_features: False  baggingclassifier__estimator__n_neighbors: 9  baggingclassifier__estimator__p: 1  baggingclassifier__estimator__weights: distance  baggingclassifier__max_features: 0.17802172282792486  baggingclassifier__max_samples: 0.6771376951247073  baggingclassifier__n_estimators: 623Best CV TPR@1% FPR: 0.5363ROC AUC at best TPR point: 0.9104################################################################################Leaderboard (by CV TPR@1% FPR)################################################################################Bagged kNN      | TPR@1%FPR:  0.5363 | ROC AUC:  0.9104