# ORIGINAL DATA SET- Dr. Xu said Junk features in data so leaned towards classifiers that implicitly select features- Because there is no detail on what each feature is, difficult to intuitively deduce anything- Examining the missingness in each feature, 299.9 missing examples per feature    - Only 3 rows with 0 missingness    - Both classes missing data at the same rate (20%)- None of the features are normal, and its not close    - Implies that mean imputation is probably not good- Some features are very poorly behaved, conside feature 16 which is always 0 in the training data when class is 1- Some features are correlated    14 & 21: 0.907269    0 & 26: 0.705438    - Consider using PCA and l1 Logistic Regression to eliminate correlated features- Obviously high dimensional data, KNN will suffer curse of dimensionality, unlikely to be good without heavy feature selection or extraction- Imputation strategy quite important here, I think for something other than## General Model Selection Outputs```Classifier: Med. Imp, PCA, KNN, Mean AUC 10-fold CV: 0.864 +/- 0.026, Mean TPR @ 1% FPR (10-fold CV): 0.268 +/- 0.092Classifier: Knn Imp, PCA, KNN, Mean AUC 10-fold CV: 0.862 +/- 0.032, Mean TPR @ 1% FPR (10-fold CV): 0.292 +/- 0.120Classifier: Med. Imp, LR(L1) FS, LR(L2), Mean AUC 10-fold CV: 0.897 +/- 0.023, Mean TPR @ 1% FPR (10-fold CV): 0.237 +/- 0.176Classifier: Med. Imp, RF, Mean AUC 10-fold CV: 0.909 +/- 0.023, Mean TPR @ 1% FPR (10-fold CV): 0.356 +/- 0.131Classifier: Knn Imp, RF, Mean AUC 10-fold CV: 0.895 +/- 0.032, Mean TPR @ 1% FPR (10-fold CV): 0.345 +/- 0.133Classifier: Med. Imp, RF FS, SVC, Mean AUC 10-fold CV: 0.814 +/- 0.035, Mean TPR @ 1% FPR (10-fold CV): 0.171 +/- 0.086Classifier: Mean Imp, Gaussian NB, Mean AUC 10-fold CV: 0.825 +/- 0.037, Mean TPR @ 1% FPR (10-fold CV): 0.157 +/- 0.093```## Model Tuning and Actual Selection- Most interesting: bagged KNN, RF, Â¿XGB?- Bagged NB is just not complex enough- Found that, using learning curves:    - RF Was massively overfitting, TPR@FPR 0.9-1 on training, less than 0.4 on testing    - Bagged KNN also overfitting but less   ### RUN 1```(10-fold, 100-iters, RS = 1)================================================================================Bagged kNN--------------------------------------------------------------------------------Best params:  baggingclassifier__bootstrap: False  baggingclassifier__bootstrap_features: True  baggingclassifier__estimator__n_neighbors: 1  baggingclassifier__estimator__p: 1  baggingclassifier__estimator__weights: distance  baggingclassifier__max_features: 0.7623351545618668  baggingclassifier__max_samples: 0.9473655792795455  baggingclassifier__n_estimators: 151Best CV TPR@1% FPR: 0.3867ROC AUC at best TPR point: 0.9022================================================================================Random Forest--------------------------------------------------------------------------------Best params:  randomforestclassifier__class_weight: balanced_subsample  randomforestclassifier__max_depth: 5  randomforestclassifier__max_features: log2  randomforestclassifier__min_samples_leaf: 4  randomforestclassifier__min_samples_split: 17  randomforestclassifier__n_estimators: 399Best CV TPR@1% FPR: 0.4013ROC AUC at best TPR point: 0.9141================================================================================XGBoost--------------------------------------------------------------------------------Best params:  xgbclassifier__colsample_bytree: 0.5326858575211132  xgbclassifier__gamma: 0.022656845652192913  xgbclassifier__learning_rate: 0.008511333444561585  xgbclassifier__max_depth: 2  xgbclassifier__min_child_weight: 2  xgbclassifier__n_estimators: 1103  xgbclassifier__reg_alpha: 0.046043516312527503  xgbclassifier__reg_lambda: 0.006075279473824769  xgbclassifier__subsample: 0.5830142409824424Best CV TPR@1% FPR: 0.4027ROC AUC at best TPR point: 0.9209################################################################################Leaderboard (by CV TPR@1% FPR)################################################################################XGBoost         | TPR@1%FPR:  0.4027 | ROC AUC:  0.9209Random Forest   | TPR@1%FPR:  0.4013 | ROC AUC:  0.9141Bagged kNN      | TPR@1%FPR:  0.3867 | ROC AUC:  0.9022```### RUN 2```Fitting 5 folds for each of 50 candidates, totalling 250 fits(RS = 420)================================================================================Bagged kNN--------------------------------------------------------------------------------Best params:  baggingclassifier__bootstrap: True  baggingclassifier__bootstrap_features: False  baggingclassifier__estimator__n_neighbors: 9  baggingclassifier__estimator__p: 1  baggingclassifier__estimator__weights: distance  baggingclassifier__max_features: 0.17802172282792486  baggingclassifier__max_samples: 0.6771376951247073  baggingclassifier__n_estimators: 623Best CV TPR@1% FPR: 0.5363ROC AUC at best TPR point: 0.9104################################################################################Leaderboard (by CV TPR@1% FPR)################################################################################Bagged kNN      | TPR@1%FPR:  0.5363 | ROC AUC:  0.9104```# After Pre-Submission- Re-ran data analysis script- Rate of missingness remains    - Still seams MCAR is a decent assumption- Still uneven classes, not spam occurs 1.5x more often- No features "pass" the shapiro-wilkes test- Re-affirms that feature 19 is the most important feature according to RF## More Tuning### Run 1```RS = 420Fitting 5 folds for each of 500 candidates, totalling 2500 fits================================================================================Bagged kNN--------------------------------------------------------------------------------Best params:  bagging__bootstrap: False  bagging__bootstrap_features: False  bagging__estimator__n_neighbors: 5  bagging__estimator__p: 1  bagging__estimator__weights: uniform  bagging__max_features: 0.32465858965554806  bagging__max_samples: 0.5040217840815863  bagging__n_estimators: 688  impute: KNNImputer(missing_values=-1, n_neighbors=9)Best CV TPR@1% FPR: 0.4706Best CV ROC AUC at best TPR point: 0.8920Fitting 5 folds for each of 500 candidates, totalling 2500 fits================================================================================Random Forest--------------------------------------------------------------------------------Best params:  impute: KNNImputer(missing_values=-1, n_neighbors=15)  rf__class_weight: {0: 1, 1: 1.0}  rf__max_depth: 16  rf__max_features: log2  rf__min_samples_leaf: 6  rf__min_samples_split: 15  rf__n_estimators: 1110Best CV TPR@1% FPR: 0.4799Best CV ROC AUC at best TPR point: 0.8872Fitting 5 folds for each of 500 candidates, totalling 2500 fits================================================================================XGBoost--------------------------------------------------------------------------------Best params:  impute: KNNImputer(missing_values=-1, n_neighbors=9, weights='distance')  xgb__colsample_bytree: 0.5226932169658256  xgb__gamma: 0.005142420307736691  xgb__learning_rate: 0.004883013892380557  xgb__max_depth: 5  xgb__min_child_weight: 6  xgb__n_estimators: 365  xgb__reg_alpha: 2.9734473221015243  xgb__reg_lambda: 0.596306560511214  xgb__subsample: 0.6994875464148346Best CV TPR@1% FPR: 0.4757Best CV ROC AUC at best TPR point: 0.8755################################################################################Leaderboard (by CV TPR@1% FPR)################################################################################Random Forest   | TPR@1%FPR:  0.4799 | ROC AUC:  0.8872XGBoost         | TPR@1%FPR:  0.4757 | ROC AUC:  0.8755Bagged kNN      | TPR@1%FPR:  0.4706 | ROC AUC:  0.8920```### Extra tree run 1 (RS = 420, scored by ROC)```================================================================================Bagged Extra Tree--------------------------------------------------------------------------------Best params:  impute: SimpleImputer(missing_values=-1)  xtree__bootstrap_features: True  xtree__estimator__class_weight: {0: 1, 1: 6.0}  xtree__estimator__max_depth: 8  xtree__estimator__max_features: None  xtree__estimator__min_samples_leaf: 7  xtree__estimator__min_samples_split: 17  xtree__max_features: 0.7616442258246028  xtree__max_samples: 0.5478679346424624  xtree__n_estimators: 879  xtree__oob_score: TrueBest CV roc_auc: 0.9034Best CV tpr at best roc_auc: 0.4647################################################################################Leaderboard (by roc_auc)################################################################################Bagged Extra Tree | roc_auc:  0.9034 | tpr:  0.4647```### Extra tree run 2 (RS = 2048, scored by ROC)```Fitting 5 folds for each of 200 candidates, totalling 1000 fits================================================================================Bagged Extra Tree--------------------------------------------------------------------------------Best params:  impute: SimpleImputer(missing_values=-1)  xtree__bootstrap_features: True  xtree__estimator__class_weight: {0: 1, 1: 3.5}  xtree__estimator__max_depth: 23  xtree__estimator__max_features: None  xtree__estimator__min_samples_leaf: 4  xtree__estimator__min_samples_split: 11  xtree__max_features: 0.6947004293985243  xtree__max_samples: 0.7647076644202585  xtree__n_estimators: 384  xtree__oob_score: FalseBest CV roc_auc: 0.9029Best CV tpr at best roc_auc: 0.4799################################################################################Leaderboard (by roc_auc)################################################################################Bagged Extra Tree | roc_auc:  0.9029 | tpr:  0.4799```### Extra Tree run 3 (RS = 123, scored by ROC)```================================================================================Bagged Extra Tree--------------------------------------------------------------------------------Best params:  impute: SimpleImputer(missing_values=-1)  xtree__bootstrap_features: False  xtree__estimator__class_weight: {0: 1, 1: 5.0}  xtree__estimator__max_depth: 29  xtree__estimator__max_features: None  xtree__estimator__min_samples_leaf: 2  xtree__estimator__min_samples_split: 7  xtree__max_features: 0.4280679716760061  xtree__max_samples: 0.28499932766190794  xtree__n_estimators: 1001  xtree__oob_score: FalseBest CV roc_auc: 0.9030Best CV tpr at best roc_auc: 0.4657################################################################################Leaderboard (by roc_auc)################################################################################Bagged Extra Tree | roc_auc:  0.9030 | tpr:  0.4657```### Xg boost run 1 (RS = 123, scored by ROC)```================================================================================XGBoost--------------------------------------------------------------------------------Best params:  xgb__colsample_bytree: 0.924477448473396  xgb__gamma: 0.3055219697397881  xgb__learning_rate: 0.00945605555473229  xgb__max_depth: 3  xgb__min_child_weight: 2  xgb__n_estimators: 1014  xgb__reg_alpha: 0.0015153764941831741  xgb__reg_lambda: 0.004829203763569532  xgb__scale_pos_weight: 0.7930483032771398  xgb__subsample: 0.7871391677310458Best CV roc_auc: 0.9087Best CV tpr at best roc_auc: 0.4322################################################################################Leaderboard (by roc_auc)################################################################################XGBoost         | roc_auc:  0.9087 | tpr:  0.4322```### Xg boost run 2 (RS = 2048, scored by ROC)```================================================================================XGBoost--------------------------------------------------------------------------------Best params:  xgb__colsample_bytree: 0.5193152153969322  xgb__gamma: 0.7862795804771125  xgb__learning_rate: 0.018189750411826484  xgb__max_depth: 6  xgb__min_child_weight: 1  xgb__n_estimators: 582  xgb__reg_alpha: 0.08183917700679029  xgb__reg_lambda: 0.04142123216155189  xgb__scale_pos_weight: 1.0125222638973157  xgb__subsample: 0.8275104000701025Best CV roc_auc: 0.9127Best CV tpr at best roc_auc: 0.5015################################################################################Leaderboard (by roc_auc)################################################################################XGBoost         | roc_auc:  0.9127 | tpr:  0.5015```### RF RUN (RS = 2834)```================================================================================Random Forest--------------------------------------------------------------------------------Best params:  impute: KNNImputer(missing_values=-1, n_neighbors=13, weights='distance')  rf__class_weight: {0: 1, 1: 2.5}  rf__max_depth: 14  rf__min_samples_leaf: 5  rf__min_samples_split: 14  rf__n_estimators: 1002  rf__oob_score: <function roc_auc_score at 0x0000022E69BE3880>Best CV tpr: 0.4816Best CV roc_auc at best tpr: 0.8925################################################################################Leaderboard (by tpr)################################################################################Random Forest   | tpr:  0.4816 | roc_auc:  0.8925``````================================================================================Bagged kNN--------------------------------------------------------------------------------Best params:  bagging__bootstrap_features: True  bagging__estimator__metric: cosine  bagging__estimator__n_neighbors: 12  bagging__estimator__weights: uniform  bagging__max_features: 0.1871344621226954  bagging__max_samples: 0.6820016278344457  bagging__n_estimators: 1058  bagging__oob_score: True  impute: SimpleImputer(missing_values=-1)Best CV tpr: 0.4648Best CV roc_auc at best tpr: 0.9027################################################################################Leaderboard (by tpr)################################################################################Bagged kNN      | tpr:  0.4648 | roc_auc:  0.9027```